{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does merge, fillna work - change values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>key1_x</th>\n",
       "      <th>Address</th>\n",
       "      <th>Qualification</th>\n",
       "      <th>key1_y</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K0</td>\n",
       "      <td>K0</td>\n",
       "      <td>Nagpur</td>\n",
       "      <td>Btech</td>\n",
       "      <td>K1</td>\n",
       "      <td>Jai</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K1</td>\n",
       "      <td>K0</td>\n",
       "      <td>Kanpur</td>\n",
       "      <td>B.A</td>\n",
       "      <td>K1</td>\n",
       "      <td>Princi</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K1</td>\n",
       "      <td>K0</td>\n",
       "      <td>Kannuaj</td>\n",
       "      <td>B.hons</td>\n",
       "      <td>K1</td>\n",
       "      <td>Princi</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K2</td>\n",
       "      <td>K0</td>\n",
       "      <td>Allahabad</td>\n",
       "      <td>Bcom</td>\n",
       "      <td>K1</td>\n",
       "      <td>Gaurav</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K1</td>\n",
       "      <td>Anuj</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key key1_x    Address Qualification key1_y    Name  Age\n",
       "0  K0     K0     Nagpur         Btech     K1     Jai   27\n",
       "1  K1     K0     Kanpur           B.A     K1  Princi   24\n",
       "2  K1     K0    Kannuaj        B.hons     K1  Princi   24\n",
       "3  K2     K0  Allahabad          Bcom     K1  Gaurav   22\n",
       "4  K3    NaN        NaN           NaN     K1    Anuj   32"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define a dictionary containing employee data \n",
    "data1 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "         'key1': ['K1', 'K1', 'K1', 'K1'],\n",
    "         'Name':['Jai', 'Princi', 'Gaurav', 'Anuj'], \n",
    "        'Age':[27, 24, 22, 32],} \n",
    "   \n",
    "# Define a dictionary containing employee data \n",
    "data0 = {'key': ['K0', 'K1', 'K2', 'K1'],\n",
    "         'key1': ['K0', 'K0', 'K0', 'K0'],\n",
    "         'Address':['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'], \n",
    "        'Qualification':['Btech', 'B.A', 'Bcom', 'B.hons']} \n",
    " \n",
    "# Convert the dictionary into DataFrame  \n",
    "df1 = pd.DataFrame(data1)\n",
    " \n",
    "# Convert the dictionary into DataFrame  \n",
    "df0 = pd.DataFrame(data0) \n",
    "\n",
    "res = pd.merge(df0, df1, how='outer', on=['key'])\n",
    " \n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B   C    D\n",
       "0  How  2.0 NaN  0.0\n",
       "1  3.0  4.0 NaN  1.0\n",
       "2  How  1.0 NaN  NaN\n",
       "3  How  3.0 NaN  4.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
    "                   [3, 4, np.nan, 1],\n",
    "                   [np.nan, np.nan, np.nan, np.nan],\n",
    "                   [np.nan, 3, np.nan, 4]],\n",
    "                  columns=list(\"ABCD\"))\n",
    "values = {\"A\": \"How\", \"B\": 1}\n",
    "df.fillna(value = values, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge all df to one df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['df_olist_geolocation_dataset.csv', 'df_olist_orders_dataset.csv', 'df_product_category_name_translation.csv', 'df_olist_customers_dataset.csv', 'df_olist_products_dataset.csv', 'df_olist_order_reviews_dataset.csv', 'df_olist_order_payments_dataset.csv', 'df_olist_sellers_dataset.csv', 'df_olist_order_items_dataset.csv']\n"
     ]
    }
   ],
   "source": [
    "from main import *\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Index(['geolocation_zip_code_prefix', 'geolocation_lat', 'geolocation_lng',\n",
       "        'geolocation_city', 'geolocation_state'],\n",
       "       dtype='object'),\n",
       " Index(['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp',\n",
       "        'order_approved_at', 'order_delivered_carrier_date',\n",
       "        'order_delivered_customer_date', 'order_estimated_delivery_date'],\n",
       "       dtype='object'),\n",
       " Index(['product_category_name', 'product_category_name_english'], dtype='object'),\n",
       " Index(['customer_id', 'customer_unique_id', 'customer_zip_code_prefix',\n",
       "        'customer_city', 'customer_state'],\n",
       "       dtype='object'),\n",
       " Index(['product_id', 'product_category_name', 'product_name_lenght',\n",
       "        'product_description_lenght', 'product_photos_qty', 'product_weight_g',\n",
       "        'product_length_cm', 'product_height_cm', 'product_width_cm'],\n",
       "       dtype='object'),\n",
       " Index(['review_id', 'order_id', 'review_score', 'review_comment_title',\n",
       "        'review_comment_message', 'review_creation_date',\n",
       "        'review_answer_timestamp'],\n",
       "       dtype='object'),\n",
       " Index(['order_id', 'payment_sequential', 'payment_type',\n",
       "        'payment_installments', 'payment_value'],\n",
       "       dtype='object'),\n",
       " Index(['seller_id', 'seller_zip_code_prefix', 'seller_city', 'seller_state'], dtype='object'),\n",
       " Index(['order_id', 'order_item_id', 'product_id', 'seller_id',\n",
       "        'shipping_limit_date', 'price', 'freight_value'],\n",
       "       dtype='object')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of all the column names in all the dataframes we downloaded from mongoDB \n",
    "all_columns = []\n",
    "for i in range(len(df_list)):\n",
    "    all_columns.append(df_list[i].columns)\n",
    "all_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp',\n",
       "       'order_approved_at', 'order_delivered_carrier_date',\n",
       "       'order_delivered_customer_date', 'order_estimated_delivery_date',\n",
       "       'review_id', 'review_score', 'review_comment_title',\n",
       "       'review_comment_message', 'review_creation_date',\n",
       "       'review_answer_timestamp', 'payment_sequential', 'payment_type',\n",
       "       'payment_installments', 'payment_value', 'order_item_id', 'product_id',\n",
       "       'seller_id', 'shipping_limit_date', 'price', 'freight_value',\n",
       "       'customer_unique_id', 'customer_zip_code_prefix', 'customer_city',\n",
       "       'customer_state', 'product_category_name', 'product_name_lenght',\n",
       "       'product_description_lenght', 'product_photos_qty', 'product_weight_g',\n",
       "       'product_length_cm', 'product_height_cm', 'product_width_cm',\n",
       "       'seller_zip_code_prefix', 'seller_city', 'seller_state'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the column names and merge them using common keys and full outer join so as not to loose any information but drawback is that full outer join will introduce NaNs\n",
    "\n",
    "final_df = pd.merge(df_list[1], df_list[5], on = \"order_id\", how = \"outer\")\n",
    "final_df = pd.merge(final_df, df_list[6], on = \"order_id\", how = \"outer\")\n",
    "final_df = pd.merge(final_df, df_list[8], on = \"order_id\", how = \"outer\")\n",
    "final_df = pd.merge(final_df, df_list[3], on = \"customer_id\", how = \"outer\")\n",
    "final_df = pd.merge(final_df, df_list[4], on = \"product_id\", how = \"outer\")\n",
    "final_df = pd.merge(final_df, df_list[7], on = \"seller_id\", how = \"outer\")\n",
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geolocation_zip_code_prefix</th>\n",
       "      <th>geolocation_lat</th>\n",
       "      <th>geolocation_lng</th>\n",
       "      <th>geolocation_city</th>\n",
       "      <th>geolocation_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1037</td>\n",
       "      <td>-23.545621</td>\n",
       "      <td>-46.639292</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1046</td>\n",
       "      <td>-23.546081</td>\n",
       "      <td>-46.644820</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1046</td>\n",
       "      <td>-23.546129</td>\n",
       "      <td>-46.642951</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1041</td>\n",
       "      <td>-23.544392</td>\n",
       "      <td>-46.639499</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1035</td>\n",
       "      <td>-23.541578</td>\n",
       "      <td>-46.641607</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geolocation_zip_code_prefix  geolocation_lat  geolocation_lng  \\\n",
       "0                         1037       -23.545621       -46.639292   \n",
       "1                         1046       -23.546081       -46.644820   \n",
       "2                         1046       -23.546129       -46.642951   \n",
       "3                         1041       -23.544392       -46.639499   \n",
       "4                         1035       -23.541578       -46.641607   \n",
       "\n",
       "  geolocation_city geolocation_state  \n",
       "0        sao paulo                SP  \n",
       "1        sao paulo                SP  \n",
       "2        sao paulo                SP  \n",
       "3        sao paulo                SP  \n",
       "4        sao paulo                SP  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not concatenating this as it will introduce NaN without adding much value unless we wish to need data for lattitude and longitude \n",
    "df_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_category_name_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beleza_saude</td>\n",
       "      <td>health_beauty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>informatica_acessorios</td>\n",
       "      <td>computers_accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>automotivo</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cama_mesa_banho</td>\n",
       "      <td>bed_bath_table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moveis_decoracao</td>\n",
       "      <td>furniture_decor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_category_name product_category_name_english\n",
       "0            beleza_saude                 health_beauty\n",
       "1  informatica_acessorios         computers_accessories\n",
       "2              automotivo                          auto\n",
       "3         cama_mesa_banho                bed_bath_table\n",
       "4        moveis_decoracao               furniture_decor"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not concatenating this dataframe as it would not add value at present but only add NaN\n",
    "df_list[2].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>...</th>\n",
       "      <th>product_name_lenght</th>\n",
       "      <th>product_description_lenght</th>\n",
       "      <th>product_photos_qty</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>product_length_cm</th>\n",
       "      <th>product_height_cm</th>\n",
       "      <th>product_width_cm</th>\n",
       "      <th>seller_zip_code_prefix</th>\n",
       "      <th>seller_city</th>\n",
       "      <th>seller_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>a7a423a542937b74dff48feaf2dd1126</td>\n",
       "      <td>247a290f66ea274a4e123ba15e1b086c</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-07-21 19:03:50</td>\n",
       "      <td>2017-07-21 19:15:12</td>\n",
       "      <td>2017-07-24 14:47:27</td>\n",
       "      <td>2017-08-28 19:46:34</td>\n",
       "      <td>2017-08-18 00:00:00</td>\n",
       "      <td>e5db1be774e0342f0998a113baf22db5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14840.0</td>\n",
       "      <td>guariba</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>341d0ee42d08b192c88aaa1c360f97e9</td>\n",
       "      <td>b5e852d38cb35637d6e92026a54bc952</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-11-29 12:07:47</td>\n",
       "      <td>2017-11-29 12:19:01</td>\n",
       "      <td>2017-12-01 15:39:04</td>\n",
       "      <td>2018-01-03 18:09:00</td>\n",
       "      <td>2017-12-22 00:00:00</td>\n",
       "      <td>f68b9b4ca3dafbd2951d3cdbfacb2811</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14840.0</td>\n",
       "      <td>guariba</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              order_id                       customer_id  \\\n",
       "1000  a7a423a542937b74dff48feaf2dd1126  247a290f66ea274a4e123ba15e1b086c   \n",
       "1001  341d0ee42d08b192c88aaa1c360f97e9  b5e852d38cb35637d6e92026a54bc952   \n",
       "\n",
       "     order_status order_purchase_timestamp    order_approved_at  \\\n",
       "1000    delivered      2017-07-21 19:03:50  2017-07-21 19:15:12   \n",
       "1001    delivered      2017-11-29 12:07:47  2017-11-29 12:19:01   \n",
       "\n",
       "     order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "1000          2017-07-24 14:47:27           2017-08-28 19:46:34   \n",
       "1001          2017-12-01 15:39:04           2018-01-03 18:09:00   \n",
       "\n",
       "     order_estimated_delivery_date                         review_id  \\\n",
       "1000           2017-08-18 00:00:00  e5db1be774e0342f0998a113baf22db5   \n",
       "1001           2017-12-22 00:00:00  f68b9b4ca3dafbd2951d3cdbfacb2811   \n",
       "\n",
       "      review_score  ... product_name_lenght product_description_lenght  \\\n",
       "1000           1.0  ...                33.0                      523.0   \n",
       "1001           3.0  ...                33.0                      523.0   \n",
       "\n",
       "     product_photos_qty product_weight_g  product_length_cm product_height_cm  \\\n",
       "1000                3.0            584.0               16.0              11.0   \n",
       "1001                3.0            584.0               16.0              11.0   \n",
       "\n",
       "      product_width_cm  seller_zip_code_prefix  seller_city seller_state  \n",
       "1000              13.0                 14840.0      guariba           SP  \n",
       "1001              13.0                 14840.0      guariba           SP  \n",
       "\n",
       "[2 rows x 39 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#randomly see two rows just like df.head()\n",
    "final_df[1000:1002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of duplicated cells just for fun\n",
    "duplicated_count = 0\n",
    "[duplicated_count+1 for value in final_df.duplicated() if value == True]\n",
    "duplicated_count\n",
    "\n",
    "#we can remove duplicates since we have date time and hence will not remove repeat orders\n",
    "final_df = final_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 119143 entries, 0 to 119142\n",
      "Data columns (total 39 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   order_id                       119143 non-null  object \n",
      " 1   customer_id                    119143 non-null  object \n",
      " 2   order_status                   119143 non-null  object \n",
      " 3   order_purchase_timestamp       119143 non-null  object \n",
      " 4   order_approved_at              118966 non-null  object \n",
      " 5   order_delivered_carrier_date   117057 non-null  object \n",
      " 6   order_delivered_customer_date  115722 non-null  object \n",
      " 7   order_estimated_delivery_date  119143 non-null  object \n",
      " 8   review_id                      118146 non-null  object \n",
      " 9   review_score                   118146 non-null  float64\n",
      " 10  review_comment_title           13989 non-null   object \n",
      " 11  review_comment_message         50245 non-null   object \n",
      " 12  review_creation_date           118146 non-null  object \n",
      " 13  review_answer_timestamp        118146 non-null  object \n",
      " 14  payment_sequential             119140 non-null  float64\n",
      " 15  payment_type                   119140 non-null  object \n",
      " 16  payment_installments           119140 non-null  float64\n",
      " 17  payment_value                  119140 non-null  float64\n",
      " 18  order_item_id                  118310 non-null  float64\n",
      " 19  product_id                     118310 non-null  object \n",
      " 20  seller_id                      118310 non-null  object \n",
      " 21  shipping_limit_date            118310 non-null  object \n",
      " 22  price                          118310 non-null  float64\n",
      " 23  freight_value                  118310 non-null  float64\n",
      " 24  customer_unique_id             119143 non-null  object \n",
      " 25  customer_zip_code_prefix       119143 non-null  int64  \n",
      " 26  customer_city                  119143 non-null  object \n",
      " 27  customer_state                 119143 non-null  object \n",
      " 28  product_category_name          116601 non-null  object \n",
      " 29  product_name_lenght            116601 non-null  float64\n",
      " 30  product_description_lenght     116601 non-null  float64\n",
      " 31  product_photos_qty             116601 non-null  float64\n",
      " 32  product_weight_g               118290 non-null  float64\n",
      " 33  product_length_cm              118290 non-null  float64\n",
      " 34  product_height_cm              118290 non-null  float64\n",
      " 35  product_width_cm               118290 non-null  float64\n",
      " 36  seller_zip_code_prefix         118310 non-null  float64\n",
      " 37  seller_city                    118310 non-null  object \n",
      " 38  seller_state                   118310 non-null  object \n",
      "dtypes: float64(15), int64(1), object(23)\n",
      "memory usage: 36.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#final_df.dtypes\n",
    "#final_df.shape\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                          0.000000\n",
       "customer_id                       0.000000\n",
       "order_status                      0.000000\n",
       "order_purchase_timestamp          0.000000\n",
       "order_approved_at                 0.000000\n",
       "order_delivered_carrier_date      0.000000\n",
       "order_delivered_customer_date     0.000000\n",
       "order_estimated_delivery_date     0.000000\n",
       "review_id                         0.836810\n",
       "review_score                      0.836810\n",
       "review_comment_title             88.258647\n",
       "review_comment_message           57.827988\n",
       "review_creation_date              0.836810\n",
       "review_answer_timestamp           0.836810\n",
       "payment_sequential                0.002518\n",
       "payment_type                      0.002518\n",
       "payment_installments              0.002518\n",
       "payment_value                     0.002518\n",
       "order_item_id                     0.699160\n",
       "product_id                        0.699160\n",
       "seller_id                         0.699160\n",
       "shipping_limit_date               0.699160\n",
       "price                             0.699160\n",
       "freight_value                     0.699160\n",
       "customer_unique_id                0.000000\n",
       "customer_zip_code_prefix          0.000000\n",
       "customer_city                     0.000000\n",
       "customer_state                    0.000000\n",
       "product_category_name             2.133571\n",
       "product_name_lenght               2.133571\n",
       "product_description_lenght        2.133571\n",
       "product_photos_qty                2.133571\n",
       "product_weight_g                  0.715946\n",
       "product_length_cm                 0.715946\n",
       "product_height_cm                 0.715946\n",
       "product_width_cm                  0.715946\n",
       "seller_zip_code_prefix            0.699160\n",
       "seller_city                       0.699160\n",
       "seller_state                      0.699160\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check any null values \n",
    "# percent of null values\n",
    "final_df.isnull().sum()*100/len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all NaN values in order_date related columns by using values in the same row\n",
    "# the below cloumns are all dateTime and same asType (now object but will change in future)\n",
    "final_df['order_delivered_customer_date'].fillna(final_df['order_delivered_carrier_date'], inplace=True)\n",
    "# order is important for me as the df['A'].fillna(df['B'], inplace=True) values in B replace same row NaN values in A not the other way\n",
    "final_df['order_delivered_carrier_date'].fillna(final_df['order_approved_at'], inplace=True)\n",
    "final_df['order_approved_at'].fillna(final_df['order_purchase_timestamp'], inplace=True)\n",
    "# now the NaN values in all the columns are replace by values in order_purchase_timestamp as they have no NaN values\n",
    "final_df['order_approved_at'].fillna(final_df['order_purchase_timestamp'], inplace=True)\n",
    "final_df['order_delivered_carrier_date'].fillna(final_df['order_purchase_timestamp'], inplace=True)\n",
    "final_df['order_delivered_customer_date'].fillna(final_df['order_purchase_timestamp'], inplace=True)\n",
    "\n",
    "# Check again for NaN values\n",
    "#final_df1.isnull().sum()*100/len(final_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna(subset=['A'], inplace=True)\n",
    "# make a copy and remove rows without product description\n",
    "final_df1 = final_df.copy()\n",
    "final_df1.dropna(subset=['product_description_lenght'], inplace=True)\n",
    "final_df1.dropna(subset=['product_height_cm'], inplace=True)\n",
    "final_df1.dropna(subset=['payment_value'], inplace=True)\n",
    "\n",
    "# Check again for NaN values\n",
    "#final_df1.isnull().sum()*100/len(final_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now only null values are related to review\n",
    "# replace review_creation_date and review_answer_timestamp with order_delivered_customer_date assuming review made in the same date also only 0.83% null values\n",
    "final_df1['review_answer_timestamp'].fillna(final_df1['order_delivered_customer_date'], inplace=True)\n",
    "final_df1['review_creation_date'].fillna(final_df1['order_delivered_customer_date'], inplace=True)\n",
    "# now only review id and review score have null values along with review_comment\n",
    "# removing rows with null review score since that is our target and we don't need null in target. A better way would be to read the reviews with null score and decide on a rating\n",
    "final_df1.dropna(subset=['review_score'], inplace=True)\n",
    "\n",
    "# Check again for NaN values\n",
    "#final_df1.isnull().sum()*100/len(final_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since only review_comment_title and review_comment_message are with NaN values replace NaN with 'no comments'\n",
    "values = {\"review_comment_title\": \"No Comments\", \"review_comment_message\": \"No Comments\"}\n",
    "final_df1.fillna(value = values, inplace = True)\n",
    "\n",
    "# Check again for NaN values\n",
    "#final_df1.isnull().sum()*100/len(final_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# could save time by just replacing reviews woth 'no comments' and removing the remaining approximately 2% rows having null values\n",
    "final_df1.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 115633 entries, 0 to 119142\n",
      "Data columns (total 63 columns):\n",
      " #   Column                              Non-Null Count   Dtype         \n",
      "---  ------                              --------------   -----         \n",
      " 0   order_id                            115633 non-null  object        \n",
      " 1   customer_id                         115633 non-null  object        \n",
      " 2   order_status                        115633 non-null  object        \n",
      " 3   order_purchase_timestamp            115633 non-null  datetime64[ns]\n",
      " 4   order_approved_at                   115633 non-null  datetime64[ns]\n",
      " 5   order_delivered_carrier_date        115633 non-null  datetime64[ns]\n",
      " 6   order_delivered_customer_date       115633 non-null  datetime64[ns]\n",
      " 7   order_estimated_delivery_date       115633 non-null  datetime64[ns]\n",
      " 8   review_id                           115633 non-null  object        \n",
      " 9   review_score                        115633 non-null  float64       \n",
      " 10  review_comment_title                115633 non-null  object        \n",
      " 11  review_comment_message              115633 non-null  object        \n",
      " 12  review_creation_date                115633 non-null  datetime64[ns]\n",
      " 13  review_answer_timestamp             115633 non-null  datetime64[ns]\n",
      " 14  payment_sequential                  115633 non-null  float64       \n",
      " 15  payment_type                        115633 non-null  object        \n",
      " 16  payment_installments                115633 non-null  float64       \n",
      " 17  payment_value                       115633 non-null  float64       \n",
      " 18  order_item_id                       115633 non-null  float64       \n",
      " 19  product_id                          115633 non-null  object        \n",
      " 20  seller_id                           115633 non-null  object        \n",
      " 21  shipping_limit_date                 115633 non-null  datetime64[ns]\n",
      " 22  price                               115633 non-null  float64       \n",
      " 23  freight_value                       115633 non-null  float64       \n",
      " 24  customer_unique_id                  115633 non-null  object        \n",
      " 25  customer_zip_code_prefix            115633 non-null  int64         \n",
      " 26  customer_city                       115633 non-null  object        \n",
      " 27  customer_state                      115633 non-null  object        \n",
      " 28  product_category_name               115633 non-null  object        \n",
      " 29  product_name_lenght                 115633 non-null  float64       \n",
      " 30  product_description_lenght          115633 non-null  float64       \n",
      " 31  product_photos_qty                  115633 non-null  float64       \n",
      " 32  product_weight_g                    115633 non-null  float64       \n",
      " 33  product_length_cm                   115633 non-null  float64       \n",
      " 34  product_height_cm                   115633 non-null  float64       \n",
      " 35  product_width_cm                    115633 non-null  float64       \n",
      " 36  seller_zip_code_prefix              115633 non-null  float64       \n",
      " 37  seller_city                         115633 non-null  object        \n",
      " 38  seller_state                        115633 non-null  object        \n",
      " 39  order_purchase_timestampday         115633 non-null  int64         \n",
      " 40  order_purchase_timestampmonth       115633 non-null  int64         \n",
      " 41  order_purchase_timestampyear        115633 non-null  int64         \n",
      " 42  order_approved_atday                115633 non-null  int64         \n",
      " 43  order_approved_atmonth              115633 non-null  int64         \n",
      " 44  order_approved_atyear               115633 non-null  int64         \n",
      " 45  order_delivered_carrier_dateday     115633 non-null  int64         \n",
      " 46  order_delivered_carrier_datemonth   115633 non-null  int64         \n",
      " 47  order_delivered_carrier_dateyear    115633 non-null  int64         \n",
      " 48  order_delivered_customer_dateday    115633 non-null  int64         \n",
      " 49  order_delivered_customer_datemonth  115633 non-null  int64         \n",
      " 50  order_delivered_customer_dateyear   115633 non-null  int64         \n",
      " 51  order_estimated_delivery_dateday    115633 non-null  int64         \n",
      " 52  order_estimated_delivery_datemonth  115633 non-null  int64         \n",
      " 53  order_estimated_delivery_dateyear   115633 non-null  int64         \n",
      " 54  review_creation_dateday             115633 non-null  int64         \n",
      " 55  review_creation_datemonth           115633 non-null  int64         \n",
      " 56  review_creation_dateyear            115633 non-null  int64         \n",
      " 57  review_answer_timestampday          115633 non-null  int64         \n",
      " 58  review_answer_timestampmonth        115633 non-null  int64         \n",
      " 59  review_answer_timestampyear         115633 non-null  int64         \n",
      " 60  shipping_limit_dateday              115633 non-null  int64         \n",
      " 61  shipping_limit_datemonth            115633 non-null  int64         \n",
      " 62  shipping_limit_dateyear             115633 non-null  int64         \n",
      "dtypes: datetime64[ns](8), float64(15), int64(25), object(15)\n",
      "memory usage: 56.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# check which features maybe converted to date time\n",
    "#final_df1[9999:10001]\n",
    "#final_df1.columns\n",
    "final_df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1549/3429759488.py:2: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  final_df1.iloc[:, 3:8] = final_df1.iloc[:, 3:8].apply(pd.to_datetime, errors='coerce')\n",
      "/tmp/ipykernel_1549/3429759488.py:3: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  final_df1.iloc[:, 12:14] = final_df1.iloc[:, 12:14].apply(pd.to_datetime, errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Convert date to DateTime\n",
    "final_df1.iloc[:, 3:8] = final_df1.iloc[:, 3:8].apply(pd.to_datetime, errors='coerce')\n",
    "final_df1.iloc[:, 12:14] = final_df1.iloc[:, 12:14].apply(pd.to_datetime, errors='coerce')\n",
    "final_df1['shipping_limit_date'] = pd.to_datetime(final_df1['shipping_limit_date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add additional columns for day, month, year for all datetime\n",
    "date_features = [col for col in final_df1.columns if final_df1[col].dtype in ['datetime64[ns]']]\n",
    "\n",
    "for col in date_features:\n",
    "    final_df1[col +\"_day\"] = final_df1[col].dt.day \n",
    "    final_df1[col +\"_month\"] = final_df1[col].dt.month\n",
    "    final_df1[col +\"_year\"] = final_df1[col].dt.year \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfinal_df1\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_df1' is not defined"
     ]
    }
   ],
   "source": [
    "final_df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to do label encoding, converting datetime from object to datetime, isna, skew plot, numerical and categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "\n",
    "1. The columns of ['geolocation_zip_code_prefix', 'geolocation_lat', 'geolocation_lng',\n",
    "        'geolocation_city', 'geolocation_state'] and ['product_category_name', 'product_category_name_english'] not considered\n",
    "2. No duplicated values\n",
    "3. Even after outer merge negligible NaN values review_comment_title=88%, review_comment_message=58%, order_delivered_customer_date=3%, order_delivered_carrier_date, product_category_name, product_name_lenght, product_description_lenght, product_photos_qty= 2% and rest less than 1%\n",
    "4. Replaced NaN values in order date related items by replaceing with values in the same row. \n",
    "5. Possible to replace product_id related fields by checking with similar product _id and having values for size, height, etc. same for seller related columns\n",
    "6. Since only 2% rows are having NaN values with product related fields we can remove the entire row or put '0' for product related data. Removed the whole rows where we have NaN values in product related fields. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
